{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4bf8aa",
   "metadata": {},
   "source": [
    "# Performing Sentiment Analysis and Topic Modelling on Collected Google Play Store Reviews Data\n",
    "\n",
    "- Collect Data \n",
    "- Ingest Data \n",
    "- Preporcess Data\n",
    "- Approach - Using Scikit Learn and Vader Sentiment Package\n",
    "- Conclusion and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a256b5ed",
   "metadata": {},
   "source": [
    "## Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa6dae5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Import Data\n",
    "from google_play_scraper import reviews_all\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5388c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(APP_ID):\n",
    "    result = reviews_all(\n",
    "        APP_ID,\n",
    "    )\n",
    "\n",
    "    print(len(result), lang)\n",
    "    with open(f\"{APP_ID}-en-list.pkl\", \"wb\") as pklfile:\n",
    "        pickle.dump(result, pklfile)\n",
    "        \n",
    "# scrape(\"com.drivetrackplusrefuel\")\n",
    "# scrape(\"com.cgt.bharatgas\")\n",
    "# scrape(\"cx.indianoil.in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79eaf61",
   "metadata": {},
   "source": [
    "## Ingest data\n",
    "The following pickle files contain data collected through google-play-scraper package in Python which uses NodeJS to scrape data from Google Play Store's batchexecute API.\n",
    "The data is filtered and preprocessed for sentiment analysis and topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3983dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca736ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "bpcl_df = pd.DataFrame(pd.read_pickle(\"com.cgt.bharatgas-en-list.pkl\"))\n",
    "iocl_df = pd.DataFrame(pd.read_pickle(\"cx.indianoil.in-en-list.pkl\"))\n",
    "hpcl_df = pd.DataFrame(pd.read_pickle(\"com.drivetrackplusrefuel-en-list.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22156b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the three dataframes\n",
    "bpcl_df[\"AppName\"] = [\"BPCL\"] * len(bpcl_df)\n",
    "hpcl_df[\"AppName\"] = [\"HPCL\"] * len(hpcl_df)\n",
    "iocl_df[\"AppName\"] = [\"IOCL\"] * len(iocl_df)\n",
    "merged_df = pd.concat([bpcl_df, iocl_df, hpcl_df])\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99233d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78837f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data collected in the last 5 years\n",
    "recent_df = merged_df[merged_df[\"at\"] >= datetime.now()-timedelta(days=(365*5))]\n",
    "len(recent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44969f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove uneccesary columns\n",
    "filtered_df = recent_df.drop(labels=[\"userImage\", \"reviewCreatedVersion\", 'replyContent', 'repliedAt', 'appVersion'], axis=1)\n",
    "filtered_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b03d271",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "Using NLTK package to remove stopwords and tokenise review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7986f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5981d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(review):\n",
    "    # Convert text to lowercase\n",
    "    review = review.lower()\n",
    "    \n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(review)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    words = \" \".join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea016311",
   "metadata": {},
   "source": [
    "## Approach - Using Scikit Learn and Vader Sentiment Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e3983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_1 = filtered_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c99ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06f1e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiments = []\n",
    "for review in filtered_df_1['content']:\n",
    "    sentiment = analyzer.polarity_scores(review)['compound']\n",
    "    if sentiment > 0:\n",
    "        sentiment='positive'\n",
    "    elif sentiment < 0:\n",
    "        sentiment='negative'\n",
    "    else:\n",
    "        sentiment='neutral'\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "filtered_df_1['sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538dea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Reviews\n",
    "filtered_df_1['preprocessed_text'] = filtered_df_1['content'].apply(preprocess_review)\n",
    "\n",
    "# Topic modeling with LDA\n",
    "vectorizer = CountVectorizer(max_features=1000, max_df=0.95, min_df=2, stop_words='english')\n",
    "document_term_matrix = vectorizer.fit_transform(filtered_df_1['preprocessed_text'])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda.fit(document_term_matrix)\n",
    "\n",
    "# Add predicted topics to dataframe\n",
    "topics = lda.transform(document_term_matrix)\n",
    "filtered_df_1['topic'] = topics.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782643bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print topics and top words\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic #{topic_idx}:\")\n",
    "    top_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]\n",
    "    print(\", \".join(top_words))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342199fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "454c3092",
   "metadata": {},
   "source": [
    "## Conclusion and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b180a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_1.to_excel(\"Topic_Sentiment.xlsx\")\n",
    "with open(\"Topic Reference.txt\", \"w\") as file:\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        file.write(f\"Topic #{topic_idx}:\\n\")\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]\n",
    "        file.write(\", \".join(top_words) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a91d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
